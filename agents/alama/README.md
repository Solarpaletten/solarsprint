# Alama — Reasoning Engine

**TASK-INFRA-02** | Solar Sprint Project

## Overview

Alama is a **reasoning and analysis agent** powered by LLaMA.
It serves as a thinking assistant for the Solar Sprint development pipeline.

**Model:** LLaMA 3.2 8B (via Ollama)
**Role:** Reasoning, analysis, GitKeeper generation, reports
**NOT:** Code executor, product developer

---

## Architecture Position

```
ARCHITECT (Leanid)
       ↓
SUPERVISOR (Dashka) ←── Alama assists here
       ↓
SENIOR ENGINEER (Claude)
       ↓
JUNIOR EXECUTOR (Qwen2.5-Coder) ← Code execution here
       ↓
GITHUB → MVP
```

---

## Capabilities

### ✅ CAN DO

| Capability | Description |
|------------|-------------|
| **Analyze repositories** | Read structure, understand architecture |
| **Generate GitKeeper** | Create single source of truth documents |
| **Write reports** | Daily summaries, task analysis |
| **Prepare checklists** | For Dashka's review |
| **Reasoning** | Think through problems, suggest approaches |

### ❌ CANNOT DO

| Restriction | Reason |
|-------------|--------|
| Write product code | That's Junior's job |
| Commit to repos | Read-only access |
| Change architecture | Architect's decision |
| Execute commands | Analysis only |

---

## Directory Structure

```
~/AI-SERVER/agents/alama/
├── runtime/              # Execution scripts
│   ├── alama.py          # Main CLI
│   └── config.yaml       # Configuration
├── prompts/              # Standardized prompts
│   ├── analyze_repo.md
│   ├── generate_gitkeeper.md
│   └── daily_report.md
├── gitkeeper/            # Generated GitKeeper files
│   └── [project]_gitkeeper.md
├── reports/              # Generated reports
│   └── [date]_report.md
├── logs/                 # Request logs
│   └── [timestamp].log
└── README.md             # This file
```

---

## Installation

### Prerequisites

- Ollama installed and running (TASK-INFRA-01)
- MacBook Pro M5 (16GB+ RAM)

### Step 1: Download LLaMA Model

```bash
# Primary model for reasoning
ollama pull llama3.2:8b

# Alternative (more stable)
ollama pull llama3.1:8b

# Verify
ollama list | grep llama
```

### Step 2: Verify Installation

```bash
# Test reasoning capability
ollama run llama3.2:8b "Analyze this problem: How should a task management system store context for resuming work after days?"
```

---

## Usage

### CLI Mode

```bash
# Analyze a repository
python runtime/alama.py analyze --repo ~/projects/solar-sprint

# Generate GitKeeper
python runtime/alama.py gitkeeper --repo ~/projects/solar-sprint --output gitkeeper/

# Generate daily report
python runtime/alama.py report --type daily --project solar-sprint
```

### Direct Ollama Mode

```bash
# Quick reasoning query
ollama run llama3.2:8b "$(cat prompts/analyze_repo.md)" < repo_structure.txt

# With context from file
cat repo_info.txt | ollama run llama3.2:8b "Analyze this repository structure and suggest improvements"
```

### HTTP API Mode

```bash
# Reasoning request
curl http://localhost:11434/api/chat \
  -d '{
    "model": "llama3:8b",
    "messages": [
      {"role": "system", "content": "You are Alama, a reasoning assistant for software architecture analysis."},
      {"role": "user", "content": "Analyze the following project structure..."}
    ]
  }'
```

---

## Prompts

### analyze_repo.md
Analyzes repository structure and provides architectural insights.

### generate_gitkeeper.md  
Creates a GitKeeper document — single source of truth for a project.

### daily_report.md
Generates daily progress summary and next steps.

See `prompts/` directory for full prompt templates.

---

## GitKeeper Format

GitKeeper is a standardized document that captures:

- Project overview
- Architecture decisions
- Current sprint scope
- Task breakdown
- Acceptance criteria
- What's done / what's next

See `../shared/standards/gitkeeper.schema.md` for the full schema.

---

## Configuration

```yaml
# runtime/config.yaml
model: llama3.2:8b
host: localhost
port: 11434
context_length: 8192
temperature: 0.3  # Lower for consistent analysis
output_format: markdown
```

---

## Integration with Pipeline

### For Dashka (Supervisor)

```python
from alama import Alama

alama = Alama()

# Get project analysis
analysis = alama.analyze_repo("~/projects/solar-sprint")
print(analysis)

# Generate GitKeeper for Claude
gitkeeper = alama.generate_gitkeeper("solar-sprint")
gitkeeper.save("gitkeeper/solar-sprint.md")
```

### For Claude (Senior Engineer)

Claude reads GitKeeper files generated by Alama as the source of truth for implementation.

---

## Model Selection

| Model | Size | Best For | RAM Usage |
|-------|------|----------|-----------|
| llama3.2:8b | 8B | Reasoning, analysis | ~6GB |
| llama3.1:8b | 8B | Stable, reliable | ~6GB |
| llama3.2:3b | 3B | Quick queries | ~3GB |

**Recommended:** `llama3.2:8b` for full reasoning capability.

---

## Troubleshooting

### Model too slow

```bash
# Use smaller model for quick queries
ollama run llama3.2:3b "Quick analysis..."
```

### Out of memory (with Qwen running)

```bash
# Unload other models first
ollama stop qwen2.5-coder:7b

# Or reduce context
ollama run llama3.2:8b --num-ctx 4096 "..."
```

### Connection refused

```bash
# Ensure Ollama is running
ollama serve

# Check port
curl http://localhost:11434/
```

---

## Logs

All Alama requests are logged to `logs/` with:

- Timestamp
- Input (prompt/repo path)
- Output (generated content)
- Model used
- Duration

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2026-01-15 | Initial setup with LLaMA 3.2 |

---

**TASK-INFRA-02** | Solar Sprint Project | Alama Reasoning Engine
